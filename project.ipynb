{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. INSTALL NECESSARY LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.3.23)\n",
      "Requirement already satisfied: langchain_community in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.3.21)\n",
      "Requirement already satisfied: discord.py in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.5.2)\n",
      "Requirement already satisfied: sentence-transformers in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.0.2)\n",
      "Requirement already satisfied: faiss-cpu in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.10.0)\n",
      "Requirement already satisfied: pypdf in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (5.4.0)\n",
      "Requirement already satisfied: llama-cpp-python in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.3.8)\n",
      "Requirement already satisfied: python-dotenv in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.1.0)\n",
      "Requirement already satisfied: nest_asyncio in /Users/ybandla/Library/Python/3.12/lib/python/site-packages (1.6.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain) (0.3.51)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain) (0.3.27)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain) (2.11.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain_community) (3.11.16)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain_community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain_community) (2.8.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain_community) (2.2.4)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers) (4.51.1)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers) (0.30.2)\n",
      "Requirement already satisfied: Pillow in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers) (4.13.1)\n",
      "Requirement already satisfied: packaging in /Users/ybandla/Library/Python/3.12/lib/python/site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: diskcache>=5.6.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama-cpp-python) (5.6.3)\n",
      "Requirement already satisfied: jinja2>=2.11.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama-cpp-python) (3.1.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.19.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2>=2.11.3->llama-cpp-python) (3.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (78.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: anyio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain langchain_community discord.py sentence-transformers faiss-cpu pypdf llama-cpp-python python-dotenv nest_asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. IMPORT NECESSARY LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import discord\n",
    "from discord.ext import commands\n",
    "import pickle\n",
    "import nest_asyncio\n",
    "import sentence_transformers\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. SET API KEYS AND DIRECTORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "PDF_DIRECTORY = \"algorithms_docs\"\n",
    "FAISS_INDEX_PATH = \"faiss_index\"\n",
    "DISCORD_TOKEN = os.getenv(\"DISCORD_TOKEN\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. LOAD PDFS WITH METADATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdfs_metadata(directory_path):\n",
    "    documents = []\n",
    "    for file in os.listdir(directory_path):\n",
    "        if file.endswith('.pdf'):\n",
    "            pdf_path = os.path.join(directory_path, file)\n",
    "            try:\n",
    "                # Determine document type from filename or folder structure\n",
    "                doc_type = \"unknown\"\n",
    "                if \"lecture\" in file.lower():\n",
    "                    doc_type = \"lecture\"\n",
    "                elif \"hw\" in file.lower():\n",
    "                    if \"sol\" in file.lower():\n",
    "                        doc_type = \"homework_solution\"\n",
    "                    else:\n",
    "                        doc_type = \"homework\"\n",
    "                elif \"review\" in file.lower():\n",
    "                    doc_type = \"exam\"\n",
    "                elif \"midterm\" in file.lower():\n",
    "                    doc_type = \"exam\"\n",
    "                elif \"practice\" in file.lower():\n",
    "                    doc_type = \"practice_problem\"\n",
    "                    \n",
    "                # Load PDF\n",
    "                loader = PyPDFLoader(pdf_path)\n",
    "                docs = loader.load()\n",
    "                    \n",
    "                    # Add metadata to each page\n",
    "                for doc in docs:\n",
    "                    doc.metadata[\"source_type\"] = doc_type\n",
    "                    doc.metadata[\"filename\"] = file\n",
    "                    \n",
    "                documents.extend(docs)\n",
    "                print(f\"Loaded: {file} as {doc_type}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {file}: {e}\")\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: HW07_sol.pdf as homework_solution\n",
      "Loaded: HW06_sol.pdf as homework_solution\n",
      "Loaded: HW05.pdf as homework\n",
      "Loaded: Lecture 02.pdf as lecture\n",
      "Loaded: HW04_sol.pdf as homework_solution\n",
      "Loaded: Lecture 03.pdf as lecture\n",
      "Loaded: HW10.pdf as homework\n",
      "Loaded: HW04.pdf as homework\n",
      "Loaded: Lecture 0.pdf as lecture\n",
      "Loaded: HW06.pdf as homework\n",
      "Loaded: PracticeProblems4.pdf as practice_problem\n",
      "Loaded: Lecture 01.pdf as lecture\n",
      "Loaded: HW07.pdf as homework\n",
      "Loaded: HW03.pdf as homework\n",
      "Loaded: Lecture 10.pdf as lecture\n",
      "Loaded: Lecture 04.pdf as lecture\n",
      "Loaded: PracticeProblems1.pdf as practice_problem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing for Object Streams\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: Lecture 05.pdf as lecture\n",
      "Loaded: Lecture 11.pdf as lecture\n",
      "Loaded: HW02.pdf as homework\n",
      "Loaded: Lecture 07.pdf as lecture\n",
      "Loaded: Lecture 13.pdf as lecture\n",
      "Loaded: PracticeProblems2.pdf as practice_problem\n",
      "Loaded: PracticeProblems3.pdf as practice_problem\n",
      "Loaded: Lecture 12.pdf as lecture\n",
      "Loaded: Lecture 06.pdf as lecture\n",
      "Loaded: HW05_sol.pdf as homework_solution\n",
      "Loaded: HW01.pdf as homework\n",
      "Loaded: HW10_sol.pdf as homework_solution\n",
      "Loaded: MidtermB.pdf as exam\n",
      "Loaded: Lecture 08.pdf as lecture\n",
      "Loaded: MidtermA.pdf as exam\n",
      "Loaded: HW09_sol.pdf as homework_solution\n",
      "Loaded: Lecture 09.pdf as lecture\n",
      "Loaded: HW08_sol.pdf as homework_solution\n",
      "Loaded: HW01_sol.pdf as homework_solution\n",
      "Loaded: HW09.pdf as homework\n",
      "Loaded: HW08.pdf as homework\n",
      "Loaded: Final Review.pdf as exam\n",
      "Loaded: HW0.pdf as homework\n",
      "Loaded: Midterm Review.pdf as exam\n",
      "Loaded: HW03_sol.pdf as homework_solution\n",
      "Loaded: HW02_sol.pdf as homework_solution\n",
      "Loaded 1014 document pages in total\n"
     ]
    }
   ],
   "source": [
    "documents = load_pdfs_metadata(PDF_DIRECTORY)\n",
    "print(f\"Loaded {len(documents)} document pages in total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document types distribution:\n",
      "- homework_solution: 43 pages\n",
      "- homework: 24 pages\n",
      "- lecture: 719 pages\n",
      "- practice_problem: 100 pages\n",
      "- exam: 128 pages\n"
     ]
    }
   ],
   "source": [
    "doc_types = {}\n",
    "for doc in documents:\n",
    "    doc_type = doc.metadata.get(\"source_type\", \"unknown\")\n",
    "    doc_types[doc_type] = doc_types.get(doc_type, 0) + 1\n",
    "\n",
    "print(\"Document types distribution:\")\n",
    "for doc_type, count in doc_types.items():\n",
    "    print(f\"- {doc_type}: {count} pages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of the first document (HW07_sol.pdf):\n",
      "Johnson and Mirzaei CS 3330 Homework 7 Solution\n",
      "Problem 1\n",
      "(a) A = [2, 6, 7, 1, 3, 5, 4]\n",
      "(b) j will never reach 6, as the loop is exclusive. It iterates through 0 to 5 for j.\n",
      "Value ofj Value ofi Array\n",
      "0 0 [2,6,7,1,3,5,4]\n",
      "1 0 [2,6,7,1,3,5,4]\n",
      "2 0 [2,6,7,1,3,5,4]\n",
      "3 1 [2,1,7,6,3,5,4]\n",
      "4 2 [2,1,3,6,7,5,4]\n",
      "5 2 [2,1,3,6,7,5,4]\n",
      "(c) A = [2, 1, 3, 4, 7, 5, 6]\n",
      "Problem 2\n",
      "(a) Taking either the smallest or the largest element of A as the pivot would lead to the worst partition.\n",
      "In this case, at each iteration, ...\n"
     ]
    }
   ],
   "source": [
    "if documents:\n",
    "    print(f\"Preview of the first document ({documents[0].metadata[\"filename\"]}):\")\n",
    "    preview_text = documents[0].page_content[:500] + \"...\" if len(documents[0].page_content) > 500 else documents[0].page_content\n",
    "    print(preview_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. CREATE CHUNKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 1560 chunks from 1014 document pages\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200, separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"])\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "print(f\"Created {len(chunks)} chunks from {len(documents)} document pages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example chunk (fromHW07_sol.pdf):\n",
      "\n",
      "Johnson and Mirzaei CS 3330 Homework 7 Solution\n",
      "Problem 1\n",
      "(a) A = [2, 6, 7, 1, 3, 5, 4]\n",
      "(b) j will never reach 6, as the loop is exclusive. It iterates through 0 to 5 for j.\n",
      "Value ofj Value ofi Array\n",
      "0 0 [2,6,7,1,3,5,4]\n",
      "1 0 [2,6,7,1,3,5,4]\n",
      "2 0 [2,6,7,1,3,5,4]\n",
      "3 1 [2,1,7,6,3,5,4]\n",
      "4 2 [2,1,3,6,7,5,4]\n",
      "...\n",
      "\n",
      "Chunk metadata: {'producer': 'pdfTeX-1.40.26', 'creator': 'TeX', 'creationdate': '2024-11-19T19:48:06+00:00', 'moddate': '2024-11-19T19:48:06+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0', 'trapped': '/False', 'source': 'algorithms_docs/HW07_sol.pdf', 'total_pages': 5, 'page': 0, 'page_label': '1', 'source_type': 'homework_solution', 'filename': 'HW07_sol.pdf'}\n"
     ]
    }
   ],
   "source": [
    "if chunks:\n",
    "    print(f\"Example chunk (from{chunks[0].metadata[\"filename\"]}):\\n\")\n",
    "    preview_chunk = chunks[0].page_content[:300] + \"...\" if len(chunks[0].page_content) > 300 else chunks[0].page_content\n",
    "    print(preview_chunk)\n",
    "    print(\"\\nChunk metadata:\", chunks[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. CREATE VECTOR STORAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created and saved to faiss_index\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name = \"all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.from_documents(documents=chunks, embedding = embeddings)\n",
    "vectorstore.save_local(FAISS_INDEX_PATH)\n",
    "print(f\"Vector store created and saved to {FAISS_INDEX_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. RETRIEVER FOR FILTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metadata_filter(doc_type):\n",
    "    def filter_func(doc):\n",
    "        return doc.metadata.get(\"source_type\") == doc_type\n",
    "    return filter_func\n",
    "\n",
    "def create_retriever(doc_type = None):\n",
    "    vs = FAISS.load_local(FAISS_INDEX_PATH, embeddings, allow_dangerous_deserialization=True)\n",
    "    if doc_type:\n",
    "        base_retriever = vs.as_retriever(search_kwargs={\"k\": 10})\n",
    "        def filtered_retriever(query):\n",
    "                docs = base_retriever.invoke(query)\n",
    "                filtered_docs = [doc for doc in docs if doc.metadata.get(\"source_type\") == doc_type]\n",
    "                return filtered_docs[:4]\n",
    "        return filtered_retriever\n",
    "    else:\n",
    "        return vs.as_retriever(search_kwargs={\"k\": 4})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. SET UP LANGUAGE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM setup completed\n"
     ]
    }
   ],
   "source": [
    "def setup_llm():\n",
    "    return HuggingFaceHub(\n",
    "        repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\",  # You can change to another model\n",
    "        model_kwargs={\"temperature\": 0.1, \"max_new_tokens\": 2048, \"n_ctx\": 4096, \"verbose\": True},\n",
    "        huggingfacehub_api_token=os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "    )\n",
    "\n",
    "# Try to setup the LLM\n",
    "try:\n",
    "    llm = setup_llm()\n",
    "    print(\"LLM setup completed\")\n",
    "except Exception as e:\n",
    "    print(f\"Error setting up LLM: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. CREATE RAG CHAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\\\n",
    "You are an algorithms teaching assistant for a computer science class.\n",
    "Answer the question based solely on the following context from class materials.\n",
    "Do not include any extra text, background information, or commentary—only your final answer.\n",
    "\n",
    "When answering:\n",
    "1. Be thorough and explain concepts clearly.\n",
    "2. Use examples to illustrate complex algorithms when appropriate.\n",
    "3. Include time and space complexity analysis when relevant.\n",
    "4. If the answer isn't fully contained in the context, say so rather than making up information.\n",
    "5. Don't hallucinate.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Chat History: {chat_history}\n",
    "\n",
    "Your final answer must start with \"Answer:\" and include nothing else.\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "retriever = self.retriever | format_docs\n",
    "\n",
    "def create_rag_chain(retriever_func):\n",
    "    if callable(retriever_func) and not hasattr(retriever_func, 'invoke'):\n",
    "        retriever_chain = RunnablePassthrough() | retriever_func | format_docs\n",
    "    else:\n",
    "        retriever_chain = retriever_func | format_docs\n",
    "    \n",
    "    chain = (\n",
    "        {\"context\": retriever_chain, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    return chain\n",
    "\n",
    "def get_rag_chain_for_thread(self, thread_id):\n",
    "    # Create a new memory if this thread doesn't have one yet\n",
    "    if thread_id not in self.thread_memories:\n",
    "        self.thread_memories[thread_id] = ConversationBufferMemory(\n",
    "            memory_key=\"chat_history\", \n",
    "            return_messages=True\n",
    "        )\n",
    "    \n",
    "    memory = self.thread_memories[thread_id]\n",
    "\n",
    "rag_chain = create_rag_chain(retriever)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. SMART DOCUMENT SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smart_query(question):\n",
    "    question_lower = question.lower()\n",
    "    if any(term in question_lower for term in [\"solution\", \"answer\", \"solved\", \"how to solve\"]):\n",
    "        print(\"Using primarily homework solutions for this query...\")\n",
    "        custom_retriever = create_retriever(\"homework_solution\")\n",
    "    elif any(term in question_lower for term in [\"lecture\", \"class\", \"taught\", \"professor\"]):\n",
    "        print(\"Using primarily lecture materials for this query...\")\n",
    "        custom_retriever = create_retriever(\"lecture\")\n",
    "    elif any(term in question_lower for term in [\"exam\", \"test\", \"quiz\", \"midterm\", \"final\"]):\n",
    "        print(\"Using primarily exam materials for this query...\")\n",
    "        custom_retriever = create_retriever(\"exam\")\n",
    "    elif any(term in question_lower for term in [\"homework\", \"assignment\", \"problem set\"]):\n",
    "        print(\"Using primarily homework materials for this query...\")\n",
    "        custom_retriever = create_retriever(\"homework\")\n",
    "    else:\n",
    "        print(\"Using all course materials for this query...\")\n",
    "        custom_retriever = create_retriever()\n",
    "    temp_chain = create_rag_chain(custom_retriever)\n",
    "    return temp_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. TEST RAG SYSTEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all course materials for this query...\n",
      "Human: You are an algorithms teaching assistant for a computer science class.\n",
      "Answer the question based solely on the following context from class materials.\n",
      "Do not include any extra text, background information, or commentary—only your final answer.\n",
      "\n",
      "When answering:\n",
      "1. Be thorough and explain concepts clearly.\n",
      "2. Use examples to illustrate complex algorithms when appropriate.\n",
      "3. Include time and space complexity analysis when relevant.\n",
      "4. If the answer isn't fully contained in the context, say so rather than making up information.\n",
      "5. Don't hallucinate.\n",
      "\n",
      "Context:\n",
      "Mergesort implementation\n",
      "tnputTFFwistFLFofFn elementsFfromFaFtotallyForderedFuniverseTF\n",
      "zutputTFF—heFnFelementsFinFascendingForderT\n",
      "c\n",
      "MERGE-SORT(L)\n",
      "\n",
      "8\n",
      "Divide and conquer: merge sort\n",
      "\n",
      "7\n",
      "Divide and conquer: merge sort\n",
      "\n",
      "Mergesort\n",
      "独”ecursivelyFsortFleftFhalfTF\n",
      "独”ecursivelyFsortFrightFhalfTF\n",
      "独xergeFtwoFhalvesFtoFmakeFsortedFwholeT\n",
      "a\n",
      "l r s t w x z ” … —\n",
      "merge results\n",
      "l w r z ” t — s x …\n",
      "input\n",
      "t — s x …l r w z ”\n",
      "sort left half\n",
      "s t x … —\n",
      "sort right half\n",
      "l r w z ”\n",
      "\n",
      "Question:\n",
      "Explain how merge-sort works\n",
      "\n",
      "Your final answer must start with \"Answer:\" and include nothing else.\n",
      "\n",
      "Answer:\n",
      "Answer: Merge-sort is a divide and conquer algorithm. It recursively sorts the left and right halves of an array, then merges the sorted halves to form a single sorted array. The merging process combines two sorted halves by comparing their elements and placing the smaller one in the result array. This process continues until the entire array is sorted. The time complexity of merge-sort is O(n log n) in the average and worst cases, and its space complexity is O(n) due to the need to store the temporary merge results.\n"
     ]
    }
   ],
   "source": [
    "test_question = \"Explain how merge-sort works\"\n",
    "try:\n",
    "    answer = smart_query(test_question)\n",
    "    print(answer)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"\\nYou may need to download a language model or start text-generation-webui.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. CREATE DISCORD BOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "class AlgorithmsBot(commands.Bot):\n",
    "    def __init__(self):\n",
    "        intents = discord.Intents.default()\n",
    "        intents.message_content = True\n",
    "        super().__init__(command_prefix=\"!\", intents=intents)\n",
    "\n",
    "    async def on_ready(self):\n",
    "        print(f'{self.user} has connected to Discord!')\n",
    "        print(f'Bot is in {len(self.guilds)} servers')\n",
    "\n",
    "    async def setup_hook(self):\n",
    "        await self.add_cog(AlgorithmsCog(self))\n",
    "\n",
    "class AlgorithmsCog(commands.Cog):\n",
    "    def __init__(self, bot):  # Accept bot parameter\n",
    "        self.bot = bot\n",
    "        self.retriever = create_retriever()\n",
    "        # Create the RAG chain\n",
    "        self.rag_chain = create_rag_chain(self.retriever)\n",
    "        self.thread_memories = {}\n",
    "\n",
    "    @commands.command(name='algo')\n",
    "    async def algo_command(self, ctx, *, question):\n",
    "\n",
    "        thread = await ctx.message.create_thread(\n",
    "            name = f\"Question: {question[:50]}...\",\n",
    "            auto_archive_duration = 60\n",
    "        )\n",
    "\n",
    "        async with thread.typing():\n",
    "            try:\n",
    "                # Invoke the chain to get the raw output.\n",
    "                raw_output = self.rag_chain.invoke(question)\n",
    "                \n",
    "                # Post-process the output to only include content after \"Answer:\"\n",
    "                if \"Answer:\" in raw_output:\n",
    "                    filtered_answer = raw_output.split(\"Answer:\")[-1].strip()\n",
    "                else:\n",
    "                    filtered_answer = raw_output.strip()\n",
    "                \n",
    "                # Build the final message displaying just the question and answer\n",
    "                response = f\"**Question:** {question}\\n\\n**Answer:** {filtered_answer}\"\n",
    "                \n",
    "                # Send the response in chunks if it is long\n",
    "                if len(response) > 1900:\n",
    "                    chunks = [response[i:i+1900] for i in range(0, len(response), 1900)]\n",
    "                    for chunk in chunks:\n",
    "                        await thread.send(chunk)\n",
    "                else:\n",
    "                    await thread.send(response)\n",
    "\n",
    "                await thread.send(\"You can ask follow-up questions in this thread!\")\n",
    "            except Exception as e:\n",
    "                await ctx.send(f\"Error: {str(e)}\")\n",
    "\n",
    "    @commands.command(name='sources')\n",
    "    async def source_filter_command(self, ctx, source_type, *, question):\n",
    "        valid_sources = [\"lecture\", \"homework\", \"homework_solution\", \"exam\", \"practice_problem\", \"all\"]\n",
    "        if source_type.lower() not in valid_sources:\n",
    "            await ctx.send(f\"Invalid source type. Use one of: {', '.join(valid_sources)}\")\n",
    "            return\n",
    "        \n",
    "        mapping = {\n",
    "        \"all\": None,\n",
    "        \"solution\": \"homework_solution\",\n",
    "        \"homework_solution\": \"homework_solution\",\n",
    "        \"lecture\": \"lecture\",\n",
    "        \"homework\": \"homework\",\n",
    "        \"exam\": \"exam\",\n",
    "        \"practice_problem\": \"practice_problem\",\n",
    "        }\n",
    "        doc_type = mapping.get(source_type.lower())\n",
    "\n",
    "        thread = await ctx.message.create_thread(\n",
    "            name = f\"Question: {question[:50]}...\",\n",
    "            auto_archive_duration = 60\n",
    "        )\n",
    "        \n",
    "        async with thread.typing():\n",
    "            try:\n",
    "                custom_retriever = create_retriever(doc_type)\n",
    "                temp_chain = create_rag_chain(custom_retriever)\n",
    "                raw_output = temp_chain.invoke(question)\n",
    "\n",
    "                if \"Answer:\" in raw_output:\n",
    "                    filtered_answer = raw_output.split(\"Answer:\")[-1].strip()\n",
    "                else:\n",
    "                    filtered_answer = raw_output.strip()\n",
    "                \n",
    "                source_display = \"all sources\" if source_type.lower() == \"all\" else f\"{source_type} materials\"\n",
    "                response = f\"**Question:** {question}\\n**Source:** {source_display}\\n\\n**Answer:** {filtered_answer}\"\n",
    "\n",
    "                if len(answer) > 1850:\n",
    "                    chunks = [answer[i:i+1850] for i in range(0, len(answer), 1850)]\n",
    "                    for i, chunk in enumerate(chunks):\n",
    "                        await thread.send(chunk)\n",
    "                else:\n",
    "                    await thread.send(response)\n",
    "            except Exception as e:\n",
    "                await thread.send(f\"Error: {str(e)}\")\n",
    "\n",
    "    @commands.command(name='help_algo')\n",
    "    async def help_command(self, ctx):      \n",
    "        help_text = (\n",
    "            \"**Algorithms Bot Commands:**\\n\\n\"\n",
    "            \"`!algo [question]` - Ask any algorithms question\\n\"\n",
    "            \"`!sources [type] [question]` - Search only specific source types\\n\"\n",
    "            \"  - Valid types: lecture, homework, solution, exam, all\\n\"\n",
    "            \"`!help_algo` - Show this help message\\n\\n\"\n",
    "            \"**Examples:**\\n\"\n",
    "            \"`!algo How does quicksort work?`\\n\"\n",
    "            \"`!sources lecture What is dynamic programming?`\"\n",
    "        )\n",
    "        await ctx.send(help_text)\n",
    "\n",
    "    @commands.Cog.listener()\n",
    "    async def on_message(self, message):\n",
    "        # Ignore messages from the bot itself\n",
    "        if message.author == self.bot.user:\n",
    "            return\n",
    "            \n",
    "        # Check if the message is in a thread\n",
    "        if isinstance(message.channel, discord.Thread):\n",
    "            # Check if this thread was created by the bot\n",
    "            if message.channel.owner_id == self.bot.user.id:\n",
    "                # Don't process commands (to avoid double processing)\n",
    "                if not message.content.startswith(self.bot.command_prefix):\n",
    "                    async with message.channel.typing():\n",
    "                        try:\n",
    "                            # Process the follow-up question\n",
    "                            raw_output = self.rag_chain.invoke(message.content)\n",
    "                            \n",
    "                            # Post-process the output\n",
    "                            if \"Answer:\" in raw_output:\n",
    "                                filtered_answer = raw_output.split(\"Answer:\")[-1].strip()\n",
    "                            else:\n",
    "                                filtered_answer = raw_output.strip()\n",
    "                            \n",
    "                            # Build the response\n",
    "                            response = f\"**Follow-up:** {message.content}\\n\\n**Answer:** {filtered_answer}\"\n",
    "                            \n",
    "                            # Send the response in chunks if needed\n",
    "                            if len(response) > 1900:\n",
    "                                chunks = [response[i:i+1900] for i in range(0, len(response), 1900)]\n",
    "                                for chunk in chunks:\n",
    "                                    await message.channel.send(chunk)\n",
    "                            else:\n",
    "                                await message.channel.send(response)\n",
    "                        except Exception as e:\n",
    "                            await message.channel.send(f\"Error processing follow-up: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-09 14:11:39] [INFO    ] discord.client: logging in using static token\n",
      "[2025-04-09 14:11:39] [INFO    ] discord.client: logging in using static token\n",
      "[2025-04-09 14:11:39] [INFO    ] discord.client: logging in using static token\n",
      "[2025-04-09 14:11:39] [INFO    ] discord.client: logging in using static token\n",
      "[2025-04-09 14:11:39] [INFO    ] discord.client: logging in using static token\n",
      "[2025-04-09 14:11:39] [INFO    ] discord.client: logging in using static token\n",
      "[2025-04-09 14:11:39] [INFO    ] discord.client: logging in using static token\n",
      "[2025-04-09 14:11:39] [INFO    ] discord.client: logging in using static token\n",
      "[2025-04-09 14:11:39] [INFO    ] discord.client: logging in using static token\n",
      "[2025-04-09 14:11:39] [INFO    ] discord.client: logging in using static token\n",
      "[2025-04-09 14:11:40] [INFO    ] discord.gateway: Shard ID None has connected to Gateway (Session ID: 35bacecb73bf485346768051ad1ddcfa).\n",
      "[2025-04-09 14:11:40] [INFO    ] discord.gateway: Shard ID None has connected to Gateway (Session ID: 35bacecb73bf485346768051ad1ddcfa).\n",
      "[2025-04-09 14:11:40] [INFO    ] discord.gateway: Shard ID None has connected to Gateway (Session ID: 35bacecb73bf485346768051ad1ddcfa).\n",
      "[2025-04-09 14:11:40] [INFO    ] discord.gateway: Shard ID None has connected to Gateway (Session ID: 35bacecb73bf485346768051ad1ddcfa).\n",
      "[2025-04-09 14:11:40] [INFO    ] discord.gateway: Shard ID None has connected to Gateway (Session ID: 35bacecb73bf485346768051ad1ddcfa).\n",
      "[2025-04-09 14:11:40] [INFO    ] discord.gateway: Shard ID None has connected to Gateway (Session ID: 35bacecb73bf485346768051ad1ddcfa).\n",
      "[2025-04-09 14:11:40] [INFO    ] discord.gateway: Shard ID None has connected to Gateway (Session ID: 35bacecb73bf485346768051ad1ddcfa).\n",
      "[2025-04-09 14:11:40] [INFO    ] discord.gateway: Shard ID None has connected to Gateway (Session ID: 35bacecb73bf485346768051ad1ddcfa).\n",
      "[2025-04-09 14:11:40] [INFO    ] discord.gateway: Shard ID None has connected to Gateway (Session ID: 35bacecb73bf485346768051ad1ddcfa).\n",
      "[2025-04-09 14:11:40] [INFO    ] discord.gateway: Shard ID None has connected to Gateway (Session ID: 35bacecb73bf485346768051ad1ddcfa).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithms RAG Bot#0980 has connected to Discord!\n",
      "Bot is in 1 servers\n"
     ]
    }
   ],
   "source": [
    "nest_asyncio.apply()\n",
    "bot = AlgorithmsBot()\n",
    "bot.run(DISCORD_TOKEN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
